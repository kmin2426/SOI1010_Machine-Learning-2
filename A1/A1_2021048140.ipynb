{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SOI1010 Machine Learning II - Assignment #1\n",
        "*   **Name**: Dongmin Kim\n",
        "*   **Dep**: Automotive Enginnering\n",
        "*   **ID**: 2021048140\n",
        "*   **Assigned**: Sep. 22, 2025\n",
        "*   **Due**: Oct. 5, 2025\n",
        "\n"
      ],
      "metadata": {
        "id": "-g1yv3ZLie9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Problem #1: Multiclass Classification via k-NN on MNIST"
      ],
      "metadata": {
        "id": "xwoD6H6ijxzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Code"
      ],
      "metadata": {
        "id": "m1LvP0Ggj3us"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dK-HX763iUmZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices for train/val splits: train_idx, valid_idx\n",
        "np.random.seed(0)\n",
        "val_ratio = 0.1\n",
        "train_size = len(trainset)\n",
        "indices = list(range(train_size))\n",
        "split_idx = int(np.floor(val_ratio * train_size))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, val_idx = indices[split_idx:], indices[:split_idx]\n",
        "\n",
        "\n",
        "train_data = trainset.data[train_idx].float()/255.\n",
        "train_labels = trainset.targets[train_idx]\n",
        "\n",
        "val_data = trainset.data[val_idx].float()/255.\n",
        "val_labels = trainset.targets[val_idx]\n",
        "\n",
        "test_data = testset.data.float()/255.\n",
        "test_labels = testset.targets"
      ],
      "metadata": {
        "id": "A_R4pXVTkAAC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Implement a k-NN algorithm (k = 5) using an iterative method (i.e., using for loop) to classify a single new example."
      ],
      "metadata": {
        "id": "eGqi9KkXlXG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Dimension\n",
        "print('testset_data: ', testset.data.shape) # [10000, 28, 28]\n",
        "print('testset_targets: ', testset.targets.shape) # [10000]\n",
        "print('trainset_data: ', trainset.data.shape) # [60000, 28, 28]\n",
        "print('trainset_targets: ', trainset.targets.shape) # [60000]\n",
        "\n",
        "print('train_data: ',train_data[0].shape) # 28 x 28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPnhTI27qsjV",
        "outputId": "2dfa760c-db8e-4f53-fdc7-c8b042fbae0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testset_data:  torch.Size([10000, 28, 28])\n",
            "testset_targets:  torch.Size([10000])\n",
            "trainset_data:  torch.Size([60000, 28, 28])\n",
            "trainset_targets:  torch.Size([60000])\n",
            "train_data:  torch.Size([28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data, train_labels\n",
        "# val_data, val_labels\n",
        "# test_data, test_labels\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Single Example\n",
        "def iterative_method(train_data: torch.Tensor,\n",
        "                     train_labels: torch.Tensor,\n",
        "                     x: torch.Tensor ,\n",
        "                     k: int = 5):\n",
        "\n",
        "    num_train = train_data.shape[0]\n",
        "    dists = torch.zeros(num_train)\n",
        "    x_flat = x.flatten()\n",
        "\n",
        "    for i in range(num_train):\n",
        "        train_vec = train_data[i].flatten()\n",
        "        diff = x_flat - train_vec\n",
        "        dists[i] = (diff ** 2).sum()\n",
        "\n",
        "\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)\n",
        "    neighbor_labels = train_labels[idx]\n",
        "    pred = torch.bincount(neighbor_labels, minlength=10).argmax().item() # Number of MNIST's classes = 10\n",
        "\n",
        "    return pred\n",
        "\n",
        "result = iterative_method(train_data, train_labels, test_data[0])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJtoOU4fHq_S",
        "outputId": "7c8d8900-5786-450c-9de8-28ed2d2c926a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (b) Implement a k-NN algorithm (k = 5) using the broadcasting concept you learned in the laboratory session to classify a single new example"
      ],
      "metadata": {
        "id": "liZT3DZrNRQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Example\n",
        "def broadcast(train_data: torch.Tensor,\n",
        "              train_labels: torch.Tensor,\n",
        "              x: torch.Tensor,\n",
        "              k: int = 5):\n",
        "\n",
        "    diff = train_data - x\n",
        "    dists = (diff ** 2).view(train_data.size(0), -1).sum(dim=1)\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)\n",
        "    neighbor_labels = train_labels[idx]\n",
        "    pred = torch.bincount(neighbor_labels, minlength=10).argmax().item()\n",
        "\n",
        "    return pred\n",
        "\n",
        "result = broadcast(train_data, train_labels, test_data[0])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QO4oGo6NTh3",
        "outputId": "1cdd87fa-8ce8-4e66-8c61-73450cdaebc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (c) Now, extend a k-NN algorithm from (b) to perform classification over all digits for all new images at once, using broadcasting (not just a single image)."
      ],
      "metadata": {
        "id": "aay1C1qhQYtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Knn Classifier\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def knn_c(train_data: torch.Tensor,\n",
        "        train_labels: torch.Tensor,\n",
        "        test_data: torch.Tensor,\n",
        "        k: int,\n",
        "        num_classes: int = 10):\n",
        "\n",
        "    # Flatten\n",
        "    N = train_data.size(0)\n",
        "    M = test_data.size(0)\n",
        "    x_train = train_data.flatten(start_dim=1) # [N, D]\n",
        "    x_test = test_data.flatten(start_dim=1)   # [M, D]\n",
        "\n",
        "    # Distance\n",
        "    te_norm = (x_test ** 2).sum(dim=1, keepdim=True)           # [M, 1]\n",
        "    tr_norm = (x_train ** 2).sum(dim=1).unsqueeze(0)           # [1, N]\n",
        "    dists = te_norm + tr_norm - 2 * (x_test @ x_train.t())  # [M, N]\n",
        "\n",
        "    # Choosing Nearest Trainset\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)   # [M, k]\n",
        "    labels = train_labels[idx]\n",
        "\n",
        "    # Counting\n",
        "    preds = []\n",
        "    for i in range(M):\n",
        "        counts = torch.bincount(labels[i], minlength=num_classes)\n",
        "        preds.append(counts.argmax().item())\n",
        "    return torch.tensor(preds)\n",
        "\n",
        "    return preds\n",
        "\n",
        "# Validation\n",
        "pred_val = knn_c(train_data, train_labels, val_data, k=5)\n",
        "val_acc = (pred_val == val_labels).float().mean().item()\n",
        "print(f\"val accuracy: {val_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZMvF4mkQpyP",
        "outputId": "887bfe5c-75e8-44be-c839-d02c33e391a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val accuracy: 97.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (d) If there is any issue from (c), what is the cause of the issue? Improve the algorithm from (c) by resolving the issue you find from (c) [Hint: Try to find a function to replace a part of your algorithm by either googling or going through PyTorch document]."
      ],
      "metadata": {
        "id": "DCn9Nemrb3jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Knn Classifier\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def knn_d(train_data: torch.Tensor,\n",
        "            train_labels: torch.Tensor,\n",
        "            test_data: torch.Tensor,\n",
        "            k: int,\n",
        "            num_classes: int = 10):\n",
        "\n",
        "    # Flatten\n",
        "    N = train_data.size(0)\n",
        "    M = test_data.size(0)\n",
        "    x_train = train_data.view(N, -1) # [N, D]\n",
        "    x_test = test_data.view(M, -1)   # [M, D]\n",
        "\n",
        "    # Distance\n",
        "    dists = torch.cdist(x_test, x_train, p=2)\n",
        "\n",
        "    # Choosing Nearest Trainset\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)   # [M, k]\n",
        "    labels = train_labels[idx]\n",
        "\n",
        "    # Counting\n",
        "    # #### torch.bincount\n",
        "    # preds = []\n",
        "    # for i in range(M):\n",
        "    #     counts = torch.bincount(labels[i], minlength=num_classes)\n",
        "    #     preds.append(counts.argmax().item())\n",
        "    # return torch.tensor(preds)\n",
        "\n",
        "    #### scatter_add\n",
        "    counts = torch.zeros(M, num_classes, dtype=torch.int64)\n",
        "    counts.scatter_add_(1, labels, torch.ones_like(labels, dtype=torch.int64))\n",
        "    preds = counts.argmax(dim=1)\n",
        "    return preds\n",
        "\n",
        "    # #### one_hot\n",
        "    # counts = F.one_hot(labels, num_classes = num_classes)\n",
        "    # counts = counts.sum(dim=1)\n",
        "    # preds = counts.argmax(dim=1)\n",
        "\n",
        "    return preds\n",
        "\n",
        "# Validation\n",
        "pred_val = knn_d(train_data, train_labels, val_data, k=5)\n",
        "acc = (pred_val == val_labels).float().mean().item()\n",
        "print(f\"val accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey1ErLXrcASs",
        "outputId": "4b97feec-1d7f-46c5-aec5-df8ec4c06f3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val accuracy: 97.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (e) What are the hyperparameters you can tune?\n",
        "Answer: k, distance metrices\n"
      ],
      "metadata": {
        "id": "leENUQLTd4ea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (f) Try at least two other options for each hyperparameter.\n"
      ],
      "metadata": {
        "id": "13aNb7vveKHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Using L2 Norm\n",
        "def knn_L2(train_data: torch.Tensor,\n",
        "            train_labels: torch.Tensor,\n",
        "            test_data: torch.Tensor,\n",
        "            k: int,\n",
        "            num_classes: int = 10):\n",
        "\n",
        "    # Flatten\n",
        "    N = train_data.size(0)\n",
        "    M = test_data.size(0)\n",
        "    x_train = train_data.view(N, -1) # [N, D]\n",
        "    x_test = test_data.view(M, -1)   # [M, D]\n",
        "\n",
        "    # Distance: L2 (squared L2 and L2 is the same result)\n",
        "    dists = torch.cdist(x_test, x_train, p=2)\n",
        "\n",
        "    # Choosing Nearest Trainset\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)   # [M, k]\n",
        "    labels = train_labels[idx]\n",
        "\n",
        "    # Counting\n",
        "    #### scatter_add\n",
        "    counts = torch.zeros(M, num_classes, dtype=torch.int64)\n",
        "    counts.scatter_add_(1, labels, torch.ones_like(labels, dtype=torch.int64))\n",
        "    preds_L2 = counts.argmax(dim=1)\n",
        "\n",
        "    return preds_L2"
      ],
      "metadata": {
        "id": "Q2O6aM6LtxcV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using L1 Norm\n",
        "def knn_L1(train_data: torch.Tensor,\n",
        "            train_labels: torch.Tensor,\n",
        "            test_data: torch.Tensor,\n",
        "            k: int,\n",
        "            num_classes: int = 10):\n",
        "\n",
        "    # Flatten\n",
        "    N = train_data.size(0)\n",
        "    M = test_data.size(0)\n",
        "    x_train = train_data.view(N, -1) # [N, D]\n",
        "    x_test = test_data.view(M, -1)   # [M, D]\n",
        "\n",
        "    # Distance: L1\n",
        "    dists = torch.cdist(x_test, x_train, p=1)\n",
        "\n",
        "    # Choosing Nearest Trainset\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)   # [M, k]\n",
        "    labels = train_labels[idx]\n",
        "\n",
        "    # Counting\n",
        "    #### scatter_add\n",
        "    counts = torch.zeros(M, num_classes, dtype=torch.int64)\n",
        "    counts.scatter_add_(1, labels, torch.ones_like(labels, dtype=torch.int64))\n",
        "    preds_L1 = counts.argmax(dim=1)\n",
        "\n",
        "    return preds_L1"
      ],
      "metadata": {
        "id": "Kg-7NY5ft2Az"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using cosine\n",
        "def knn_cos(train_data: torch.Tensor,\n",
        "            train_labels: torch.Tensor,\n",
        "            test_data: torch.Tensor,\n",
        "            k: int,\n",
        "            num_classes: int = 10):\n",
        "\n",
        "    # Flatten\n",
        "    N = train_data.size(0)\n",
        "    M = test_data.size(0)\n",
        "    x_train = train_data.view(N, -1) # [N, D]\n",
        "    x_test = test_data.view(M, -1)   # [M, D]\n",
        "\n",
        "    # Distance: Cos\n",
        "    dot = x_test @ x_train.t()                       # [M, N]\n",
        "    norm_test = x_test.norm(dim=1, keepdim=True)     # [M, 1]\n",
        "    norm_train = x_train.norm(dim=1).unsqueeze(0)    # [1, N]\n",
        "    sim = dot / (norm_test * norm_train + 1e-8)      # [M, N]\n",
        "    dists = 1 - sim\n",
        "\n",
        "    # Choosing Nearest Trainset\n",
        "    __, idx = torch.topk(dists, k=k, largest=False)   # [M, k]\n",
        "    labels = train_labels[idx]\n",
        "\n",
        "    # Counting\n",
        "    #### scatter_add\n",
        "    counts = torch.zeros(M, num_classes, dtype=torch.int64)\n",
        "    counts.scatter_add_(1, labels, torch.ones_like(labels, dtype=torch.int64))\n",
        "    preds_cos = counts.argmax(dim=1)\n",
        "\n",
        "    return preds_cos"
      ],
      "metadata": {
        "id": "rRZOg_qmuN33"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement\n",
        "# Running Time: 1hour\n",
        "# Explore the Hyperparameter\n",
        "for i in range(10):\n",
        "    pred_val_L1 = knn_L1(train_data, train_labels, val_data, k=i)\n",
        "    pred_val_L2 = knn_L2(train_data, train_labels, val_data, k=i)\n",
        "    pred_val_cos = knn_cos(train_data, train_labels, val_data, k=i)\n",
        "    acc_L1 = (pred_val_L1 == val_labels).float().mean().item()\n",
        "    acc_L2 = (pred_val_L2 == val_labels).float().mean().item()\n",
        "    acc_cos = (pred_val_cos == val_labels).float().mean().item()\n",
        "    print(f\"{i} val accuracy (L1): {acc_L1 * 100:.2f}%\")\n",
        "    print(f\"{i} val accuracy (L2): {acc_L2 * 100:.2f}%\")\n",
        "    print(f\"{i} val accuracy (cos): {acc_cos * 100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffLH2VBmeT3u",
        "outputId": "325fbf40-fff4-4a91-f46f-b6ff1233e001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 val accuracy (L1): 10.08%\n",
            "0 val accuracy (L2): 10.08%\n",
            "0 val accuracy (cos): 10.08%\n",
            "1 val accuracy (L1): 96.77%\n",
            "1 val accuracy (L2): 97.47%\n",
            "1 val accuracy (cos): 97.97%\n",
            "2 val accuracy (L1): 95.78%\n",
            "2 val accuracy (L2): 96.78%\n",
            "2 val accuracy (cos): 97.55%\n",
            "3 val accuracy (L1): 96.93%\n",
            "3 val accuracy (L2): 97.55%\n",
            "3 val accuracy (cos): 97.97%\n",
            "4 val accuracy (L1): 96.48%\n",
            "4 val accuracy (L2): 97.27%\n",
            "4 val accuracy (cos): 98.00%\n",
            "5 val accuracy (L1): 96.47%\n",
            "5 val accuracy (L2): 97.27%\n",
            "5 val accuracy (cos): 98.02%\n",
            "6 val accuracy (L1): 96.43%\n",
            "6 val accuracy (L2): 97.27%\n",
            "6 val accuracy (cos): 97.85%\n",
            "7 val accuracy (L1): 96.60%\n",
            "7 val accuracy (L2): 97.23%\n",
            "7 val accuracy (cos): 97.85%\n",
            "8 val accuracy (L1): 96.42%\n",
            "8 val accuracy (L2): 97.20%\n",
            "8 val accuracy (cos): 97.73%\n",
            "9 val accuracy (L1): 96.37%\n",
            "9 val accuracy (L2): 97.12%\n",
            "9 val accuracy (cos): 97.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (g) You can try more options if you want. What is the final test accuracy?"
      ],
      "metadata": {
        "id": "KojMhqzUeQNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_cos = knn_cos(train_data, train_labels, test_data, k=5)\n",
        "acc_test_cos = (pred_test_cos == test_labels).float().mean().item()\n",
        "print(f\"test accuracy (k=5, cos): {acc_test_cos * 100:.2f}%\")\n",
        "\n",
        "pred_test_L1 = knn_L1(train_data, train_labels, test_data, k=5)\n",
        "acc_test_L1 = (pred_test_L1 == test_labels).float().mean().item()\n",
        "print(f\"test accuracy (k=5, L1): {acc_test_L1 * 100:.2f}%\")\n",
        "\n",
        "pred_test_L2 = knn_L2(train_data, train_labels, test_data, k=5)\n",
        "acc_test_L2 = (pred_test_L2 == test_labels).float().mean().item()\n",
        "print(f\"test accuracy (k=5, L2): {acc_test_L2 * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex9wV1p2JRS9",
        "outputId": "7b3bc89f-f93e-4bb0-a9f8-1640fc612720"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy (k=5, cos): 97.22%\n",
            "test accuracy (k=5, L1): 96.07%\n",
            "test accuracy (k=5, L2): 96.66%\n"
          ]
        }
      ]
    }
  ]
}
